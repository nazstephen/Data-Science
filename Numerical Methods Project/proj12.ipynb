{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Methods Project <a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "Rusty Bargain used car sales service is developing an app to attract new customers. In that app, you can quickly find out the market value of your car. You have access to historical data: technical specifications, trim versions, and prices. You need to build the model to determine the value. \n",
    "\n",
    "Rusty Bargain is interested in:\n",
    "\n",
    "- the quality of the prediction;\n",
    "- the speed of the prediction;\n",
    "- the time required for training\n",
    "\n",
    "## Project instructions\n",
    "1) Download and look at the data.\n",
    "2) Train different models with various hyperparameters. Compare gradient boosting methods with random forest, decision tree, and linear regression.\n",
    "3) Analyze the speed and quality of the models.\n",
    "\n",
    "## Data description\n",
    "The dataset is stored in file `/datasets/car_data.csv`. download dataset.\n",
    "\n",
    "### Features\n",
    "- **DateCrawled** — date profile was downloaded from the database\n",
    "- **VehicleType** — vehicle body type\n",
    "- **RegistrationYear** — vehicle registration year\n",
    "- **Gearbox** — gearbox type\n",
    "- **Power** — power (hp)\n",
    "- **Model** — vehicle model\n",
    "- **Mileage** — mileage (measured in km due to dataset's regional specifics)\n",
    "- **RegistrationMonth** — vehicle registration month\n",
    "- **FuelType** — fuel type\n",
    "- **Brand** — vehicle brand\n",
    "- **NotRepaired** — vehicle repaired or not\n",
    "- **DateCreated** — date of profile creation\n",
    "- **NumberOfPictures** — number of vehicle pictures\n",
    "- **PostalCode** — postal code of profile owner (user)\n",
    "- **LastSeen** — date of the last activity of the user\n",
    "\n",
    "###  Target\n",
    "- **Price** — price (Euro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car_data.csv' file successfully read from the local path.\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_name, local_path, server_path):\n",
    "    try:\n",
    "        data = pd.read_csv(local_path + file_name)\n",
    "        print(f\"'{file_name}' file successfully read from the local path.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            data = pd.read_csv(server_path + file_name)\n",
    "            print(f\"'{file_name}' file successfully read from the server path.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"'{file_name}' file not found. Please check the file paths.\")\n",
    "            data = None\n",
    "            \n",
    "    return data\n",
    "\n",
    "file_name = 'car_data.csv'\n",
    "local_path = '/Users/benjaminstephen/Documents/TripleTen/Sprint_12/Numerical_Methods_Project/datasets/'\n",
    "server_path = '/datasets/'\n",
    "\n",
    "df = load_data(file_name, local_path, server_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we will conduct basic exploratory data analysis and clean the data to ensure it is optimally prepared for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/03/2016 11:52</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>07/04/2016 03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24/03/2016 10:58</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>07/04/2016 01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/03/2016 12:52</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>05/04/2016 12:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17/03/2016 16:54</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>17/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>17/03/2016 17:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/03/2016 17:25</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>31/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>06/04/2016 10:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354364</th>\n",
       "      <td>21/03/2016 09:50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>colt</td>\n",
       "      <td>150000</td>\n",
       "      <td>7</td>\n",
       "      <td>petrol</td>\n",
       "      <td>mitsubishi</td>\n",
       "      <td>yes</td>\n",
       "      <td>21/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2694</td>\n",
       "      <td>21/03/2016 10:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354365</th>\n",
       "      <td>14/03/2016 17:48</td>\n",
       "      <td>2200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sonstige_autos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>39576</td>\n",
       "      <td>06/04/2016 00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354366</th>\n",
       "      <td>05/03/2016 19:56</td>\n",
       "      <td>1199</td>\n",
       "      <td>convertible</td>\n",
       "      <td>2000</td>\n",
       "      <td>auto</td>\n",
       "      <td>101</td>\n",
       "      <td>fortwo</td>\n",
       "      <td>125000</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>smart</td>\n",
       "      <td>no</td>\n",
       "      <td>05/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>26135</td>\n",
       "      <td>11/03/2016 18:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354367</th>\n",
       "      <td>19/03/2016 18:57</td>\n",
       "      <td>9200</td>\n",
       "      <td>bus</td>\n",
       "      <td>1996</td>\n",
       "      <td>manual</td>\n",
       "      <td>102</td>\n",
       "      <td>transporter</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>19/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>87439</td>\n",
       "      <td>07/04/2016 07:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354368</th>\n",
       "      <td>20/03/2016 19:41</td>\n",
       "      <td>3400</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2002</td>\n",
       "      <td>manual</td>\n",
       "      <td>100</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>40764</td>\n",
       "      <td>24/03/2016 12:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354369 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateCrawled  Price  VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "0       24/03/2016 11:52    480          NaN              1993  manual      0   \n",
       "1       24/03/2016 10:58  18300        coupe              2011  manual    190   \n",
       "2       14/03/2016 12:52   9800          suv              2004    auto    163   \n",
       "3       17/03/2016 16:54   1500        small              2001  manual     75   \n",
       "4       31/03/2016 17:25   3600        small              2008  manual     69   \n",
       "...                  ...    ...          ...               ...     ...    ...   \n",
       "354364  21/03/2016 09:50      0          NaN              2005  manual      0   \n",
       "354365  14/03/2016 17:48   2200          NaN              2005     NaN      0   \n",
       "354366  05/03/2016 19:56   1199  convertible              2000    auto    101   \n",
       "354367  19/03/2016 18:57   9200          bus              1996  manual    102   \n",
       "354368  20/03/2016 19:41   3400        wagon              2002  manual    100   \n",
       "\n",
       "              Model  Mileage  RegistrationMonth  FuelType           Brand  \\\n",
       "0              golf   150000                  0    petrol      volkswagen   \n",
       "1               NaN   125000                  5  gasoline            audi   \n",
       "2             grand   125000                  8  gasoline            jeep   \n",
       "3              golf   150000                  6    petrol      volkswagen   \n",
       "4             fabia    90000                  7  gasoline           skoda   \n",
       "...             ...      ...                ...       ...             ...   \n",
       "354364         colt   150000                  7    petrol      mitsubishi   \n",
       "354365          NaN    20000                  1       NaN  sonstige_autos   \n",
       "354366       fortwo   125000                  3    petrol           smart   \n",
       "354367  transporter   150000                  3  gasoline      volkswagen   \n",
       "354368         golf   150000                  6  gasoline      volkswagen   \n",
       "\n",
       "       NotRepaired       DateCreated  NumberOfPictures  PostalCode  \\\n",
       "0              NaN  24/03/2016 00:00                 0       70435   \n",
       "1              yes  24/03/2016 00:00                 0       66954   \n",
       "2              NaN  14/03/2016 00:00                 0       90480   \n",
       "3               no  17/03/2016 00:00                 0       91074   \n",
       "4               no  31/03/2016 00:00                 0       60437   \n",
       "...            ...               ...               ...         ...   \n",
       "354364         yes  21/03/2016 00:00                 0        2694   \n",
       "354365         NaN  14/03/2016 00:00                 0       39576   \n",
       "354366          no  05/03/2016 00:00                 0       26135   \n",
       "354367          no  19/03/2016 00:00                 0       87439   \n",
       "354368         NaN  20/03/2016 00:00                 0       40764   \n",
       "\n",
       "                LastSeen  \n",
       "0       07/04/2016 03:16  \n",
       "1       07/04/2016 01:46  \n",
       "2       05/04/2016 12:47  \n",
       "3       17/03/2016 17:40  \n",
       "4       06/04/2016 10:17  \n",
       "...                  ...  \n",
       "354364  21/03/2016 10:42  \n",
       "354365  06/04/2016 00:46  \n",
       "354366  11/03/2016 18:17  \n",
       "354367  07/04/2016 07:15  \n",
       "354368  24/03/2016 12:45  \n",
       "\n",
       "[354369 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Mileage            354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This DataFrame consists of 354,369 vehicle listings with attributes such as price, vehicle type, and mileage. Several columns, including VehicleType, Gearbox, Model, and FuelType, have missing values, which could impact the accuracy of analyses and models. The NotRepaired column also has significant missing values, suggesting that repair status is frequently undisclosed and may affect assessments of vehicle condition. The Price column, being fully populated, serves as a reliable target variable for machine learning models. To ensure robust predictions, it will be important to address the missing values and consider how these gaps may influence the model’s performance.\n",
    "\n",
    "Let's begin the preprocessing by checking for and handling any duplicate rows in the dataset. This step is crucial to ensure data integrity and avoid skewing the analysis or model training with redundant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF DUPLICATED ROWS: 262\n"
     ]
    }
   ],
   "source": [
    "print(\"NUMBER OF DUPLICATED ROWS:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 262 duplicated rows in the dataset. We will handle this by removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF DUPLICATED ROWS: 0\n"
     ]
    }
   ],
   "source": [
    "new_df = df.drop_duplicates()\n",
    "print(\"NUMBER OF DUPLICATED ROWS:\", new_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 354107 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354107 non-null  object\n",
      " 1   Price              354107 non-null  int64 \n",
      " 2   VehicleType        316623 non-null  object\n",
      " 3   RegistrationYear   354107 non-null  int64 \n",
      " 4   Gearbox            334277 non-null  object\n",
      " 5   Power              354107 non-null  int64 \n",
      " 6   Model              334406 non-null  object\n",
      " 7   Mileage            354107 non-null  int64 \n",
      " 8   RegistrationMonth  354107 non-null  int64 \n",
      " 9   FuelType           321218 non-null  object\n",
      " 10  Brand              354107 non-null  object\n",
      " 11  NotRepaired        282962 non-null  object\n",
      " 12  DateCreated        354107 non-null  object\n",
      " 13  NumberOfPictures   354107 non-null  int64 \n",
      " 14  PostalCode         354107 non-null  int64 \n",
      " 15  LastSeen           354107 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 45.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(new_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after eliminating duplicate rows, there are still null values in the dataset that need to be addressed. To ensure the dataset is in optimal condition for data splitting, we should remove these null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCENTAGE OF NULL VALUES:\n",
      "--------------------------\n",
      "DateCrawled          0.0\n",
      "Price                0.0\n",
      "VehicleType          0.0\n",
      "RegistrationYear     0.0\n",
      "Gearbox              0.0\n",
      "Power                0.0\n",
      "Model                0.0\n",
      "Mileage              0.0\n",
      "RegistrationMonth    0.0\n",
      "FuelType             0.0\n",
      "Brand                0.0\n",
      "NotRepaired          0.0\n",
      "DateCreated          0.0\n",
      "NumberOfPictures     0.0\n",
      "PostalCode           0.0\n",
      "LastSeen             0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "new_df = new_df.dropna() \n",
    "\n",
    "print(\"PERCENTAGE OF NULL VALUES:\")\n",
    "print(\"--------------------------\")\n",
    "print(new_df.isnull().sum()/len(new_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all null values addressed, the dataset is now ready to be divided into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now proceed with splitting the data, excluding the features 'DateCrawled', 'Price', 'DateCreated', 'NumberOfPictures', 'PostalCode', and 'LastSeen' from the analysis. These features are deemed irrelevant to the vehicle's selling price and will not be included in the dataset used for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the feature variables\n",
    "features = new_df.drop(['DateCrawled', 'Price', 'DateCreated', 'NumberOfPictures', 'PostalCode', 'LastSeen'], axis=1)\n",
    "\n",
    "# Extract the target variable 'Price'\n",
    "target = new_df['Price']\n",
    "\n",
    "# Split data: 60% for training, 20% for validation, and 20% for testing\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size=0.4, random_state=12345)\n",
    "\n",
    "# Further split the remaining 40% into validation (20%) and test (20%) sets\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_temp, target_temp, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data split correctly, we will now encode our categorical variables using two methods: label encoding and one-hot encoding. Label encoding will be used for training all of our models except XGBoost, as it effectively converts categories into ordinal values suitable for most algorithms. For XGBoost, we will apply one-hot encoding because it handles categorical variables by converting them into binary features. One-hot encoding allows XGBoost to treat each category as a distinct feature, avoiding any unintended ordinal relationships and improving the model's ability to capture complex patterns and interactions in the data. This approach ensures that each model is trained with the most appropriate encoding method for its requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply One-Hot encoding to the categorical features in the training, validation, and test sets using the 'one_hot_encode_categrocial_features' function. This function converts categorical variables into binary columns and merges them with the remaining numeric features. After encoding, we will ensure that all sets have the same feature columns by reindexing and filling any missing columns with zeros. This step guarantees consistency across the datasets. Finally, we will print the dimensions of the one-hot encoded training, validation, and test sets to verify the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Feature Set Size (One-Hot Encoded): (147340, 311)\n",
      "\n",
      "Validation Feature Set Size (One-Hot Encoded): (49113, 311)\n",
      "\n",
      "Test Feature Set Size (One-Hot Encoded): (49114, 311)\n"
     ]
    }
   ],
   "source": [
    "# Function to one-hot encode specified categorical features\n",
    "def one_hot_encode_categrocial_features(all_features, categorical_features):\n",
    "    # Create one-hot encoded columns for the specified categorical features\n",
    "    categorical_features_ohe = pd.get_dummies(all_features[categorical_features])\n",
    "    # Drop the original categorical columns from the dataset\n",
    "    numeric_features = all_features.drop(columns=categorical_features)\n",
    "    # Concatenate the numeric features with the one-hot encoded columns\n",
    "    return pd.concat([numeric_features, categorical_features_ohe], axis=1)\n",
    "\n",
    "# Apply one-hot encoding to the training, validation, and test sets\n",
    "features_train_ohe = one_hot_encode_categrocial_features(features_train, categorical_features)\n",
    "features_valid_ohe = one_hot_encode_categrocial_features(features_valid, categorical_features)\n",
    "features_test_ohe = one_hot_encode_categrocial_features(features_test, categorical_features)\n",
    "\n",
    "# Ensure all datasets have the same columns by combining columns from all sets\n",
    "all_columns = features_train_ohe.columns.union(features_valid_ohe.columns).union(features_test_ohe.columns)\n",
    "\n",
    "# Reindex each dataset to include all columns, filling missing columns with zeros\n",
    "features_train_ohe = features_train_ohe.reindex(columns=all_columns, fill_value=0)\n",
    "features_valid_ohe = features_valid_ohe.reindex(columns=all_columns, fill_value=0)\n",
    "features_test_ohe = features_test_ohe.reindex(columns=all_columns, fill_value=0)\n",
    "\n",
    "# Print the size of each one-hot encoded feature set\n",
    "print('Training Feature Set Size (One-Hot Encoded):', features_train_ohe.shape)\n",
    "print()\n",
    "print('Validation Feature Set Size (One-Hot Encoded):', features_valid_ohe.shape)\n",
    "print()\n",
    "print('Test Feature Set Size (One-Hot Encoded):', features_test_ohe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we will initialize an OrdinalEncoder to handle categorical features, with special handling for unknown values set to -1. We wil first fit the encoder using the categorical features from the training set, which allows it to learn the encoding scheme based on these categories. Next, we will apply this encoding to the categorical features in the training, validation, and test sets, converting them into ordinal values. This ensures that all datasets are consistently encoded for further analysis or model training. Finally, we will print the sizes of the datasets to confirm that the label encoding has been applied correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Feature Set Size (Label Encoded): (147340, 10)\n",
      "\n",
      "Validation Feature Set Size (Label Encoded): (49113, 10)\n",
      "\n",
      "Test Feature Set Size (Label Encoded): (49114, 10)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the OrdinalEncoder with handling for unknown values\n",
    "label_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Fit the encoder on the categorical features from the training set\n",
    "label_encoder.fit(features_train[categorical_features])\n",
    "\n",
    "# Transform the categorical features in the training set to ordinal values\n",
    "features_train[categorical_features] = label_encoder.transform(features_train[categorical_features])\n",
    "\n",
    "# Transform the categorical features in the validation set to ordinal values\n",
    "features_valid[categorical_features] = label_encoder.transform(features_valid[categorical_features])\n",
    "\n",
    "# Transform the categorical features in the test set to ordinal values\n",
    "features_test[categorical_features] = label_encoder.transform(features_test[categorical_features])\n",
    "\n",
    "# Print the size of each dataset after label encoding\n",
    "print('Training Feature Set Size (Label Encoded):', features_train.shape)\n",
    "print()\n",
    "print('Validation Feature Set Size (Label Encoded):', features_valid.shape)\n",
    "print()\n",
    "print('Test Feature Set Size (Label Encoded):', features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data successfully preprocessed, we can now proceed to use it for training various machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model training, our focus will be on evaluating Root Mean Squared Error (RMSE), training time, and prediction time across various machine learning models, both with and without hyperparameter tuning. To streamline this repetitive process, I have developed a function designed to expedite and simplify the evaluation.\n",
    "\n",
    "The function below assesses a machine learning model by calculating key performance metrics. It measures the time required for both model training and making predictions on the validation set, and computes the RMSE to gauge prediction accuracy. By printing and returning these metrics, the function aids in analyzing the efficiency and effectiveness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, features_train=features_train, features_valid=features_valid, target_train=target_train, target_valid=target_valid):\n",
    "    # Record the start time for model training\n",
    "    training_start_time = time.time()\n",
    "    # Train the model on the training data\n",
    "    model.fit(features_train, target_train)\n",
    "    # Calculate the time taken to train the model\n",
    "    training_time = time.time() - training_start_time\n",
    "\n",
    "    # Record the start time for making predictions\n",
    "    prediction_start_time = time.time()\n",
    "    # Generate predictions on the validation set\n",
    "    predictions = model.predict(features_valid)\n",
    "    # Calculate the time taken to make predictions\n",
    "    prediction_time = time.time() - prediction_start_time\n",
    "\n",
    "    # Compute the total time taken for training and prediction\n",
    "    total_time = training_time + prediction_time\n",
    "\n",
    "    # Calculate the Root Mean Squared Error (RMSE) of the predictions\n",
    "    rmse = np.sqrt(mean_squared_error(target_valid, predictions))\n",
    "\n",
    "    # Print out the RMSE, training time, prediction time, and total time\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"Training Time:\", training_time)\n",
    "    print(\"Prediction Time:\", prediction_time)\n",
    "    print(\"Total Time:\", total_time)\n",
    "\n",
    "    # Return RMSE, training time, prediction time, and total time\n",
    "    return rmse, training_time, prediction_time, total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a Linear Regression model. While linear regression is not ideal for hyperparameter tuning, it serves as a valuable benchmark for assessing other methods. For example, if gradient boosting underperforms compared to linear regression, it indicates that there may be an issue with the implementation or configuration of the gradient boosting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3374.7387690525256\n",
      "Training Time: 0.027150869369506836\n",
      "Prediction Time: 0.0031061172485351562\n",
      "Total Time: 0.030256986618041992\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_rmse, lr_training_time, lr_prediction_time, lr_total_time = model_eval(lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1676.1741708358006\n",
      "Training Time: 25.355262994766235\n",
      "Prediction Time: 1.154905080795288\n",
      "Total Time: 26.510168075561523\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(random_state=12345)\n",
    "\n",
    "rf_rmse, rf_training_time, rf_prediction_time, rf_total_time = model_eval(rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (w/ Hyperparamter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1674.8222844314166\n",
      "Training Time: 20.060376167297363\n",
      "Prediction Time: 0.6625418663024902\n",
      "Total Time: 20.722918033599854\n"
     ]
    }
   ],
   "source": [
    "tuned_rf_model = RandomForestRegressor(\n",
    "    random_state=12345,\n",
    "    n_estimators=100,            \n",
    "    max_depth=20,                \n",
    "    min_samples_split=5, \n",
    "    min_samples_leaf=4,          \n",
    ")\n",
    "\n",
    "tuned_rf_rmse, tuned_rf_training_time, tuned_rf_prediction_time, tuned_rf_total_time = model_eval(tuned_rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1751.5396013597624\n",
      "Training Time: 0.28572726249694824\n",
      "Prediction Time: 0.03445887565612793\n",
      "Total Time: 0.32018613815307617\n"
     ]
    }
   ],
   "source": [
    "lgbm_model = LGBMRegressor(random_state=12345, verbose=-1)\n",
    "\n",
    "lgbm_rmse, lgbm_training_time, lgbm_prediction_time, lgbm_total_time = model_eval(lgbm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM (w/ Hyperparamter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1717.2707056682807\n",
      "Training Time: 0.33321380615234375\n",
      "Prediction Time: 0.04467415809631348\n",
      "Total Time: 0.3778879642486572\n"
     ]
    }
   ],
   "source": [
    "tuned_lgbm_model = LGBMRegressor(\n",
    "    random_state=12345,\n",
    "    n_estimators=150,           \n",
    "    max_depth=15,                \n",
    "    learning_rate=0.1,           \n",
    "    num_leaves=31,               \n",
    "    min_child_samples=20,        \n",
    "    subsample=0.8,              \n",
    "    colsample_bytree=0.8,\n",
    "    verbose=-1        \n",
    ")\n",
    "\n",
    "tuned_lgbm_rmse, tuned_lgbm_training_time, tuned_lgbm_prediction_time, tuned_lgbm_total_time = model_eval(tuned_lgbm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1667.2774539344996\n",
      "Training Time: 3.5843520164489746\n",
      "Prediction Time: 0.008485794067382812\n",
      "Total Time: 3.5928378105163574\n"
     ]
    }
   ],
   "source": [
    "cb_model = CatBoostRegressor(random_state=12345, verbose=False)\n",
    "\n",
    "cb_rmse, cb_training_time, cb_prediction_time, cb_total_time = model_eval(cb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost (w/ Hyperparamter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1660.827068507683\n",
      "Training Time: 4.325237989425659\n",
      "Prediction Time: 0.004136085510253906\n",
      "Total Time: 4.329374074935913\n"
     ]
    }
   ],
   "source": [
    "tuned_cb_model = CatBoostRegressor(\n",
    "    random_state=12345,\n",
    "    depth=13,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=175,\n",
    "    l2_leaf_reg=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bylevel=0.8,\n",
    "    verbose=0 \n",
    ")\n",
    "\n",
    "tuned_cb_rmse, tuned_cb_training_time, tuned_cb_prediction_time, tuned_cb_total_time = model_eval(tuned_cb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: For XGBoost, we will use our one-hot encoded features to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1704.8133441061075\n",
      "Training Time: 13.957070112228394\n",
      "Prediction Time: 0.03068399429321289\n",
      "Total Time: 13.987754106521606\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(random_state=12345)\n",
    "\n",
    "xgb_rmse, xgb_training_time, xgb_prediction_time, xgb_total_time = model_eval(xgb_model, \n",
    "                                                                              features_train_ohe, \n",
    "                                                                              features_valid_ohe, \n",
    "                                                                              target_train, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost (w/ Hyperparamter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1597.500036904102\n",
      "Training Time: 32.80623984336853\n",
      "Prediction Time: 0.05894017219543457\n",
      "Total Time: 32.865180015563965\n"
     ]
    }
   ],
   "source": [
    "tuned_xgb_model = XGBRegressor(\n",
    "    random_state=12345,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=15,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    ")\n",
    "\n",
    "tuned_xgb_rmse, tuned_xgb_training_time, tuned_xgb_prediction_time, tuned_xgb_total_time = model_eval(tuned_xgb_model, \n",
    "                                                                                                      features_train_ohe, \n",
    "                                                                                                      features_valid_ohe, \n",
    "                                                                                                      target_train, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained and tested all our models using the validation set, we will now analyze their performance to identify which model will be most beneficial for Rusty Bargain. To facilitate comparison and draw conclusions, we will compile their statistics into a single data frame. This will make it easier to evaluate and compare the models' effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Prediction Time</th>\n",
       "      <th>Total Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>3374.738769</td>\n",
       "      <td>0.027151</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.030257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1676.174171</td>\n",
       "      <td>25.355263</td>\n",
       "      <td>1.154905</td>\n",
       "      <td>26.510168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (Tuned)</td>\n",
       "      <td>1674.822284</td>\n",
       "      <td>20.060376</td>\n",
       "      <td>0.662542</td>\n",
       "      <td>20.722918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1751.539601</td>\n",
       "      <td>0.285727</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>0.320186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM (Tuned)</td>\n",
       "      <td>1717.270706</td>\n",
       "      <td>0.333214</td>\n",
       "      <td>0.044674</td>\n",
       "      <td>0.377888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>1667.277454</td>\n",
       "      <td>3.584352</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>3.592838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost (Tuned)</td>\n",
       "      <td>1660.827069</td>\n",
       "      <td>4.325238</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>4.329374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1704.813344</td>\n",
       "      <td>13.957070</td>\n",
       "      <td>0.030684</td>\n",
       "      <td>13.987754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost (Tuned)</td>\n",
       "      <td>1597.500037</td>\n",
       "      <td>32.806240</td>\n",
       "      <td>0.058940</td>\n",
       "      <td>32.865180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model         RMSE  Training Time  Prediction Time  \\\n",
       "0      Linear Regression  3374.738769       0.027151         0.003106   \n",
       "1          Random Forest  1676.174171      25.355263         1.154905   \n",
       "2  Random Forest (Tuned)  1674.822284      20.060376         0.662542   \n",
       "3               LightGBM  1751.539601       0.285727         0.034459   \n",
       "4       LightGBM (Tuned)  1717.270706       0.333214         0.044674   \n",
       "5               CatBoost  1667.277454       3.584352         0.008486   \n",
       "6       CatBoost (Tuned)  1660.827069       4.325238         0.004136   \n",
       "7                XGBoost  1704.813344      13.957070         0.030684   \n",
       "8        XGBoost (Tuned)  1597.500037      32.806240         0.058940   \n",
       "\n",
       "   Total Time  \n",
       "0    0.030257  \n",
       "1   26.510168  \n",
       "2   20.722918  \n",
       "3    0.320186  \n",
       "4    0.377888  \n",
       "5    3.592838  \n",
       "6    4.329374  \n",
       "7   13.987754  \n",
       "8   32.865180  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_analysis = pd.DataFrame({'Model': ['Linear Regression', \n",
    "                                         'Random Forest', \n",
    "                                         'Random Forest (Tuned)',\n",
    "                                         'LightGBM', \n",
    "                                         'LightGBM (Tuned)',\n",
    "                                         'CatBoost',\n",
    "                                         'CatBoost (Tuned)',\n",
    "                                         'XGBoost',\n",
    "                                         'XGBoost (Tuned)'],\n",
    "\n",
    "                                'RMSE': [lr_rmse, \n",
    "                                         rf_rmse, \n",
    "                                         tuned_rf_rmse,\n",
    "                                         lgbm_rmse, \n",
    "                                         tuned_lgbm_rmse,\n",
    "                                         cb_rmse, \n",
    "                                         tuned_cb_rmse,\n",
    "                                         xgb_rmse,\n",
    "                                         tuned_xgb_rmse],\n",
    "                                \n",
    "                                'Training Time': [lr_training_time, \n",
    "                                                  rf_training_time,\n",
    "                                                  tuned_rf_training_time, \n",
    "                                                  lgbm_training_time,\n",
    "                                                  tuned_lgbm_training_time, \n",
    "                                                  cb_training_time, \n",
    "                                                  tuned_cb_training_time,\n",
    "                                                  xgb_training_time,\n",
    "                                                  tuned_xgb_training_time],\n",
    "                                \n",
    "                                'Prediction Time': [lr_prediction_time, \n",
    "                                                    rf_prediction_time, \n",
    "                                                    tuned_rf_prediction_time,\n",
    "                                                    lgbm_prediction_time, \n",
    "                                                    tuned_lgbm_prediction_time,\n",
    "                                                    cb_prediction_time, \n",
    "                                                    tuned_cb_prediction_time,\n",
    "                                                    xgb_prediction_time,\n",
    "                                                    tuned_xgb_prediction_time],\n",
    "                                \n",
    "                                'Total Time': [lr_total_time, \n",
    "                                               rf_total_time, \n",
    "                                               tuned_rf_total_time,\n",
    "                                               lgbm_total_time,\n",
    "                                               tuned_lgbm_total_time, \n",
    "                                               cb_total_time, \n",
    "                                               tuned_cb_total_time,\n",
    "                                               xgb_total_time,\n",
    "                                               tuned_xgb_total_time]})\n",
    "\n",
    "display(model_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table summarizes the performance of various models, including RMSE, training time, prediction time, and total time. Linear Regression shows the highest RMSE of 3374.74 but is the quickest in both training and prediction. Random Forest, particularly with tuned hyperparameters, achieves a lower RMSE of 1674.82 but comes with considerably longer training and prediction times. LightGBM, both tuned and untuned, offers competitive RMSE scores with efficient training and prediction times, making it a strong contender. CatBoost, especially when tuned, provides the lowest RMSE of 1660.83 with reasonable training and prediction times, while XGBoost, although effective, has the highest total time when tuned, despite a lower RMSE.\n",
    "\n",
    "Based on this analysis, LightGBM (Tuned), CatBoost (Tuned), and XGBoost (Tuned) appear to be the top contenders for Rusty Bargain. To determine the best model, we will evaluate their performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Final RMSE: 1712.0534912835524\n",
      "LightGBM Final Training Time: 0.33321380615234375\n",
      "LightGBM Final Prediction Time: 0.04717421531677246\n",
      "LightGBM Final Total Time: 0.3803880214691162\n"
     ]
    }
   ],
   "source": [
    "tuned_lgbm_final_prediction_start_time = time.time()\n",
    "tuned_lgbm_final_predictions = tuned_lgbm_model.predict(features_test)\n",
    "tuned_lgbm_final_prediction_time = time.time() - tuned_lgbm_final_prediction_start_time\n",
    "\n",
    "tuned_lgbm_final_rmse = np.sqrt(mean_squared_error(target_test, tuned_lgbm_final_predictions))\n",
    "\n",
    "print(\"LightGBM Final RMSE:\", tuned_lgbm_final_rmse)\n",
    "print(\"LightGBM Final Training Time:\", tuned_lgbm_training_time)\n",
    "print(\"LightGBM Final Prediction Time:\", tuned_lgbm_final_prediction_time)\n",
    "print(\"LightGBM Final Total Time:\", tuned_lgbm_training_time + tuned_lgbm_final_prediction_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Final RMSE: 1659.6126984532825\n",
      "CatBoost Final Training Time: 4.325237989425659\n",
      "CatBoost Final Prediction Time: 0.004703044891357422\n",
      "CatBoost Final Total Time: 4.329941034317017\n"
     ]
    }
   ],
   "source": [
    "tuned_cb_final_prediction_start_time = time.time()\n",
    "tuned_cb_final_predictions = tuned_cb_model.predict(features_test)\n",
    "tuned_cb_final_prediction_time = time.time() - tuned_cb_final_prediction_start_time\n",
    "\n",
    "tuned_cb_final_rmse = np.sqrt(mean_squared_error(target_test, tuned_cb_final_predictions))\n",
    "\n",
    "print(\"CatBoost Final RMSE:\", tuned_cb_final_rmse)\n",
    "print(\"CatBoost Final Training Time:\", tuned_cb_training_time)\n",
    "print(\"CatBoost Final Prediction Time:\", tuned_cb_final_prediction_time)\n",
    "print(\"CatBoost Final Total Time:\", tuned_cb_training_time + tuned_cb_final_prediction_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Final RMSE: 1596.005244658428\n",
      "XGBoost Final Training Time: 32.80623984336853\n",
      "XGBoost Final Prediction Time: 0.06579709053039551\n",
      "XGBoost Final Total Time: 32.872036933898926\n"
     ]
    }
   ],
   "source": [
    "tuned_xgb_final_prediction_start_time = time.time()\n",
    "tuned_xgb_final_predictions = tuned_xgb_model.predict(features_test_ohe)\n",
    "tuned_xgb_final_prediction_time = time.time() - tuned_xgb_final_prediction_start_time\n",
    "\n",
    "tuned_xgb_final_rmse = np.sqrt(mean_squared_error(target_test, tuned_xgb_final_predictions))\n",
    "\n",
    "print(\"XGBoost Final RMSE:\", tuned_xgb_final_rmse)\n",
    "print(\"XGBoost Final Training Time:\", tuned_xgb_training_time)\n",
    "print(\"XGBoost Final Prediction Time:\", tuned_xgb_final_prediction_time)\n",
    "print(\"XGBoost Final Total Time:\", tuned_xgb_training_time + tuned_xgb_final_prediction_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final evaluation results reveal the following for each model: LightGBM achieves an RMSE of 1712.05 with a training time of 0.34 seconds and a prediction time of 0.045 seconds, resulting in a total time of 0.39 seconds. CatBoost delivers a lower RMSE of 1659.61 but has a significantly longer training time of 3.87 seconds and a brief prediction time of 0.007 seconds, with a total time of 3.88 seconds. XGBoost, despite its lowest RMSE of 1596.01, has the highest training time of 36.44 seconds and a prediction time of 0.055 seconds, leading to a total time of 36.49 seconds.\n",
    "\n",
    "Given these results, while XGBoost provides the lowest RMSE, its high total time makes it less practical. CatBoost offers a competitive RMSE with reasonable total time but still requires more time compared to LightGBM. LightGBM, with its efficient training and prediction times and a slightly higher RMSE than CatBoost, presents a balanced trade-off between performance and efficiency. Therefore, Rusty Bargain should consider using LightGBM as it provides a good compromise between accuracy and computational efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 'x' to check. Then press Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook is open\n",
    "- [x]  Code is error free\n",
    "- [x]  The cells with the code have been arranged in order of execution\n",
    "- [x]  The data has been downloaded and prepared\n",
    "- [x]  The models have been trained\n",
    "- [x]  The analysis of speed and quality of the models has been performed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
